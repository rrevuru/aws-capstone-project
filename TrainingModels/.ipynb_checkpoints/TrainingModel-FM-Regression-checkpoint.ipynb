{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import boto3,io,json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "sage_client = boto3.Session().client('sagemaker')\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying dataset from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('run-1607268992801-part-r-00000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping columns (timestamp), and changing the userid as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df.userid == 'userId'].index)\n",
    "df.userid = df.userid.astype(int)\n",
    "df.movieid = df.movieid.astype(int)\n",
    "df.rating = df.rating.astype(float)\n",
    "df = df.drop('timestamp', axis=1)\n",
    "df = df.set_index('userid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['rating'].values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a sparse matrix (Users to movies)by using One-hot encoder technique  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore',sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encoder.fit_transform(df).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data repositiories for input/output and model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'movies-mlready-bucket'\n",
    "prefix = 'fm-regression'\n",
    "train_key      = 'train.protobuf'\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train')\n",
    "test_key       = 'test.protobuf'\n",
    "test_prefix    = '{}/{}'.format(prefix, 'test')\n",
    "output_prefix  = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to convert input data to record-io format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data S3 path:  s3://movies-mlready-bucket/fm-regression/train/train.protobuf\n",
      "Test data S3 path:  s3://movies-mlready-bucket/fm-regression/test/test.protobuf\n",
      "FM model output S3 path: s3://movies-mlready-bucket/fm-regression/output\n"
     ]
    }
   ],
   "source": [
    "def writeDatasetToProtobuf(X, bucket, prefix, key, d_type, Y=None):\n",
    "    buf = io.BytesIO()\n",
    "    if d_type == \"sparse\":\n",
    "        smac.write_spmatrix_to_sparse_tensor(buf, X, labels=Y)\n",
    "    else:\n",
    "        smac.write_numpy_to_dense_tensor(buf, X, labels=Y)\n",
    "        \n",
    "    buf.seek(0)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket,obj)\n",
    "    \n",
    "fm_regression_train_data_path = writeDatasetToProtobuf(X_train, bucket, train_prefix, train_key, \"sparse\", y_train)\n",
    "fm_regression_test_data_path  = writeDatasetToProtobuf(X_test, bucket, test_prefix, test_key, \"sparse\", y_test)\n",
    "\n",
    "  \n",
    "print (\"Training data S3 path: \",fm_regression_train_data_path)\n",
    "print (\"Test data S3 path: \",fm_regression_test_data_path)\n",
    "print (\"FM model output S3 path: {}\".format(output_prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Factorization Machines Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = 'arn:aws:iam::719009365707:role/role_sagemaker'\n",
    "instance_type='ml.m5.large'\n",
    "features= 9734\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_regression = sagemaker.estimator.Estimator(get_image_uri(boto3.Session().region_name, \"factorization-machines\"),\n",
    "                                   role, \n",
    "                                   train_instance_count=1, \n",
    "                                   train_instance_type=instance_type,\n",
    "                                   base_job_name='FM-Regression-prod2',\n",
    "                                   output_path=output_prefix,\n",
    "                                   sagemaker_session=sagemaker.Session())\n",
    "\n",
    "fm_regression.set_hyperparameters(feature_dim=features,\n",
    "                      predictor_type='regressor',\n",
    "                      mini_batch_size=1000,\n",
    "                      num_factors=64,\n",
    "                      epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Auto-tuning job with HyperParameter Optimization (HPO) objective metrics and HPO parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name='test:accuracy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {'bias_init_sigma': ContinuousParameter(1e-8,2),\n",
    "                         'bias_lr': ContinuousParameter(1e-8,2),\n",
    "                         'bias_wd': ContinuousParameter(1e-8,2),\n",
    "                         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_regression = HyperparameterTuner(fm_regression,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            objective_type='Minimize'\n",
    "                            base_tuning_job_name='FM-Regression',\n",
    "                            max_jobs=5,\n",
    "                            max_parallel_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the HPO tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_regression.fit({'train': fm_regression_train_data_path, 'test': fm_regression_test_data_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Best model which is provided by Hyperparameter tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-06 16:38:23 Starting - Preparing the instances for training\n",
      "2021-01-06 16:38:23 Downloading - Downloading input data\n",
      "2021-01-06 16:38:23 Training - Training image download completed. Training in progress.\n",
      "2021-01-06 16:38:23 Uploading - Uploading generated training model\n",
      "2021-01-06 16:38:23 Completed - Training job completed\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/pandas/util/nosetester.py:13: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing import nosetester\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:41 INFO 140480896128832] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:41 INFO 140480896128832] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'predictor_type': u'regressor', u'_tuning_objective_metric': u'test:rmse', u'bias_wd': u'0.00024077590640695303', u'bias_init_sigma': u'1.9999994916751205', u'epochs': u'50', u'feature_dim': u'9734', u'bias_lr': u'3.001703959949728e-08', u'num_factors': u'64', u'mini_batch_size': u'1000'}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:41 INFO 140480896128832] Final configuration: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': u'50', u'feature_dim': u'9734', u'num_factors': u'64', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'test:rmse', u'bias_wd': u'0.00024077590640695303', u'use_linear': u'true', u'bias_lr': u'3.001703959949728e-08', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'regressor', u'bias_init_sigma': u'1.9999994916751205', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:41 WARNING 140480896128832] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:41 INFO 140480896128832] Using default worker.\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:41.923] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:41.931] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 13, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:41 INFO 140480896128832] nvidia-smi took: 0.025162935257 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:41 INFO 140480896128832] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:41 INFO 140480896128832] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:41 INFO 140480896128832] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 44.52204704284668, \"sum\": 44.52204704284668, \"min\": 44.52204704284668}}, \"EndTime\": 1609951061.973403, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951061.917249}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1609951061.973889, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951061.973829}\n",
      "\u001b[0m\n",
      "\u001b[34m[16:37:41] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.203343.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[16:37:41] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.203343.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:42 INFO 140480896128832] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=1.38704195177\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:42 INFO 140480896128832] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=1.92388537598\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:42 INFO 140480896128832] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=1.07759631348\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:42.619] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 590, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:42 INFO 140480896128832] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.40886543891\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:42 INFO 140480896128832] #quality_metric: host=algo-1, epoch=0, train mse <loss>=1.98490182495\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:42 INFO 140480896128832] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=1.07750068306\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 50, \"sum\": 50.0, \"min\": 50}, \"update.time\": {\"count\": 1, \"max\": 646.3360786437988, \"sum\": 646.3360786437988, \"min\": 646.3360786437988}}, \"EndTime\": 1609951062.62066, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951061.973747}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:42 INFO 140480896128832] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 69, \"sum\": 69.0, \"min\": 69}, \"Total Records Seen\": {\"count\": 1, \"max\": 68560, \"sum\": 68560.0, \"min\": 68560}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1609951062.620912, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1609951061.974288}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:42 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=104463.850451 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:42 INFO 140480896128832] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=1.32461774962\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:42 INFO 140480896128832] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=1.75461218262\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:42 INFO 140480896128832] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=1.00121398926\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:43.329] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 707, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:43 INFO 140480896128832] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=1.34757946153\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:43 INFO 140480896128832] #quality_metric: host=algo-1, epoch=1, train mse <loss>=1.81597040513\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:43 INFO 140480896128832] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=1.00181158268\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 709.5179557800293, \"sum\": 709.5179557800293, \"min\": 709.5179557800293}}, \"EndTime\": 1609951063.330702, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951062.620746}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:43 INFO 140480896128832] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 137, \"sum\": 137.0, \"min\": 137}, \"Total Records Seen\": {\"count\": 1, \"max\": 136120, \"sum\": 136120.0, \"min\": 136120}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1609951063.331127, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 1}, \"StartTime\": 1609951062.621153}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:43 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=95133.6484589 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:43 INFO 140480896128832] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=1.26081382022\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:43 INFO 140480896128832] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=1.58965148926\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:43 INFO 140480896128832] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=0.925578613281\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:44.005] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 671, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=1.28537393045\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #quality_metric: host=algo-1, epoch=2, train mse <loss>=1.65218614107\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.925871049769\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 674.691915512085, \"sum\": 674.691915512085, \"min\": 674.691915512085}}, \"EndTime\": 1609951064.006289, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951063.33082}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 205, \"sum\": 205.0, \"min\": 205}, \"Total Records Seen\": {\"count\": 1, \"max\": 203680, \"sum\": 203680.0, \"min\": 203680}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1609951064.006777, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 2}, \"StartTime\": 1609951063.331564}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=100003.556728 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=1.19698198363\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=1.43276586914\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=0.84993951416\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:44.732] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 724, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=1.22394879908\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #quality_metric: host=algo-1, epoch=3, train mse <loss>=1.49805066277\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=0.850409378949\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 726.3369560241699, \"sum\": 726.3369560241699, \"min\": 726.3369560241699}}, \"EndTime\": 1609951064.733796, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951064.006518}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 273, \"sum\": 273.0, \"min\": 273}, \"Total Records Seen\": {\"count\": 1, \"max\": 271240, \"sum\": 271240.0, \"min\": 271240}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1609951064.734211, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 3}, \"StartTime\": 1609951064.007371}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=92932.5309207 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=1.13449363403\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=1.28707580566\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:44 INFO 140480896128832] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=0.776048828125\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:45.496] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 760, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:45 INFO 140480896128832] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=1.16440551321\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:45 INFO 140480896128832] #quality_metric: host=algo-1, epoch=4, train mse <loss>=1.35584019919\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:45 INFO 140480896128832] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=0.778513238346\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 763.096809387207, \"sum\": 763.096809387207, \"min\": 763.096809387207}}, \"EndTime\": 1609951065.497799, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951064.733869}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:45 INFO 140480896128832] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 341, \"sum\": 341.0, \"min\": 341}, \"Total Records Seen\": {\"count\": 1, \"max\": 338800, \"sum\": 338800.0, \"min\": 338800}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1609951065.498401, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 4}, \"StartTime\": 1609951064.73467}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:45 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=88420.9932881 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:45 INFO 140480896128832] #quality_metric: host=algo-1, epoch=5, batch=0 train rmse <loss>=1.07418409035\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:45 INFO 140480896128832] #quality_metric: host=algo-1, epoch=5, batch=0 train mse <loss>=1.15387145996\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:45 INFO 140480896128832] #quality_metric: host=algo-1, epoch=5, batch=0 train absolute_loss <loss>=0.708334533691\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:46.192] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 691, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #quality_metric: host=algo-1, epoch=5, train rmse <loss>=1.10735793369\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #quality_metric: host=algo-1, epoch=5, train mse <loss>=1.2262415933\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #quality_metric: host=algo-1, epoch=5, train absolute_loss <loss>=0.716044521556\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 694.037914276123, \"sum\": 694.037914276123, \"min\": 694.037914276123}}, \"EndTime\": 1609951066.192997, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951065.498077}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 409, \"sum\": 409.0, \"min\": 409}, \"Total Records Seen\": {\"count\": 1, \"max\": 406360, \"sum\": 406360.0, \"min\": 406360}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1609951066.193289, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 5}, \"StartTime\": 1609951065.498926}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=97278.4884042 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #quality_metric: host=algo-1, epoch=6, batch=0 train rmse <loss>=1.01643711521\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #quality_metric: host=algo-1, epoch=6, batch=0 train mse <loss>=1.03314440918\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #quality_metric: host=algo-1, epoch=6, batch=0 train absolute_loss <loss>=0.651079528809\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:46.860] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 665, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #quality_metric: host=algo-1, epoch=6, train rmse <loss>=1.05304038008\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #quality_metric: host=algo-1, epoch=6, train mse <loss>=1.10889404207\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #quality_metric: host=algo-1, epoch=6, train absolute_loss <loss>=0.661276865342\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 667.9558753967285, \"sum\": 667.9558753967285, \"min\": 667.9558753967285}}, \"EndTime\": 1609951066.861584, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951066.193078}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 477, \"sum\": 477.0, \"min\": 477}, \"Total Records Seen\": {\"count\": 1, \"max\": 473920, \"sum\": 473920.0, \"min\": 473920}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1609951066.861812, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 6}, \"StartTime\": 1609951066.193596}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=101084.908045 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #quality_metric: host=algo-1, epoch=7, batch=0 train rmse <loss>=0.96134217216\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #quality_metric: host=algo-1, epoch=7, batch=0 train mse <loss>=0.924178771973\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:46 INFO 140480896128832] #quality_metric: host=algo-1, epoch=7, batch=0 train absolute_loss <loss>=0.599165649414\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:47.425] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 561, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:47 INFO 140480896128832] #quality_metric: host=algo-1, epoch=7, train rmse <loss>=1.0015283632\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:47 INFO 140480896128832] #quality_metric: host=algo-1, epoch=7, train mse <loss>=1.00305906228\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:47 INFO 140480896128832] #quality_metric: host=algo-1, epoch=7, train absolute_loss <loss>=0.609504238353\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 563.403844833374, \"sum\": 563.403844833374, \"min\": 563.403844833374}}, \"EndTime\": 1609951067.425487, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951066.861661}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:47 INFO 140480896128832] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 545, \"sum\": 545.0, \"min\": 545}, \"Total Records Seen\": {\"count\": 1, \"max\": 541480, \"sum\": 541480.0, \"min\": 541480}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1609951067.425714, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 7}, \"StartTime\": 1609951066.862053}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:47 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=119833.10155 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:47 INFO 140480896128832] #quality_metric: host=algo-1, epoch=8, batch=0 train rmse <loss>=0.908965456265\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:47 INFO 140480896128832] #quality_metric: host=algo-1, epoch=8, batch=0 train mse <loss>=0.826218200684\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:47 INFO 140480896128832] #quality_metric: host=algo-1, epoch=8, batch=0 train absolute_loss <loss>=0.549326965332\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:48.012] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 584, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #quality_metric: host=algo-1, epoch=8, train rmse <loss>=0.952945148623\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #quality_metric: host=algo-1, epoch=8, train mse <loss>=0.908104456284\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #quality_metric: host=algo-1, epoch=8, train absolute_loss <loss>=0.559985352011\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 586.8511199951172, \"sum\": 586.8511199951172, \"min\": 586.8511199951172}}, \"EndTime\": 1609951068.012895, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951067.42556}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 613, \"sum\": 613.0, \"min\": 613}, \"Total Records Seen\": {\"count\": 1, \"max\": 609040, \"sum\": 609040.0, \"min\": 609040}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1609951068.01322, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 8}, \"StartTime\": 1609951067.425962}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=115021.398829 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #quality_metric: host=algo-1, epoch=9, batch=0 train rmse <loss>=0.859450635876\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #quality_metric: host=algo-1, epoch=9, batch=0 train mse <loss>=0.738655395508\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #quality_metric: host=algo-1, epoch=9, batch=0 train absolute_loss <loss>=0.50218069458\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:48.589] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 574, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #quality_metric: host=algo-1, epoch=9, train rmse <loss>=0.907433324827\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #quality_metric: host=algo-1, epoch=9, train mse <loss>=0.823435239006\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #quality_metric: host=algo-1, epoch=9, train absolute_loss <loss>=0.514167462517\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 576.7800807952881, \"sum\": 576.7800807952881, \"min\": 576.7800807952881}}, \"EndTime\": 1609951068.590427, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951068.012963}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 681, \"sum\": 681.0, \"min\": 681}, \"Total Records Seen\": {\"count\": 1, \"max\": 676600, \"sum\": 676600.0, \"min\": 676600}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1609951068.590738, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 9}, \"StartTime\": 1609951068.013566}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=117019.021816 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #quality_metric: host=algo-1, epoch=10, batch=0 train rmse <loss>=0.812899503646\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #quality_metric: host=algo-1, epoch=10, batch=0 train mse <loss>=0.660805603027\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:48 INFO 140480896128832] #quality_metric: host=algo-1, epoch=10, batch=0 train absolute_loss <loss>=0.460259033203\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:49.151] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 558, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #quality_metric: host=algo-1, epoch=10, train rmse <loss>=0.865045383616\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #quality_metric: host=algo-1, epoch=10, train mse <loss>=0.748303515715\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #quality_metric: host=algo-1, epoch=10, train absolute_loss <loss>=0.473655328638\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 560.7380867004395, \"sum\": 560.7380867004395, \"min\": 560.7380867004395}}, \"EndTime\": 1609951069.151861, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951068.590501}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 749, \"sum\": 749.0, \"min\": 749}, \"Total Records Seen\": {\"count\": 1, \"max\": 744160, \"sum\": 744160.0, \"min\": 744160}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1609951069.152188, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 10}, \"StartTime\": 1609951068.591061}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=120364.507234 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #quality_metric: host=algo-1, epoch=11, batch=0 train rmse <loss>=0.769293784744\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #quality_metric: host=algo-1, epoch=11, batch=0 train mse <loss>=0.591812927246\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #quality_metric: host=algo-1, epoch=11, batch=0 train absolute_loss <loss>=0.423460449219\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:49.694] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 541, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #quality_metric: host=algo-1, epoch=11, train rmse <loss>=0.825717796814\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #quality_metric: host=algo-1, epoch=11, train mse <loss>=0.681809879976\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #quality_metric: host=algo-1, epoch=11, train absolute_loss <loss>=0.438185200411\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 543.0901050567627, \"sum\": 543.0901050567627, \"min\": 543.0901050567627}}, \"EndTime\": 1609951069.69564, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951069.151928}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 817, \"sum\": 817.0, \"min\": 817}, \"Total Records Seen\": {\"count\": 1, \"max\": 811720, \"sum\": 811720.0, \"min\": 811720}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1609951069.695953, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 11}, \"StartTime\": 1609951069.152522}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=124289.682998 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #quality_metric: host=algo-1, epoch=12, batch=0 train rmse <loss>=0.728505508475\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #quality_metric: host=algo-1, epoch=12, batch=0 train mse <loss>=0.530720275879\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:49 INFO 140480896128832] #quality_metric: host=algo-1, epoch=12, batch=0 train absolute_loss <loss>=0.390637695312\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:50.255] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 558, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #quality_metric: host=algo-1, epoch=12, train rmse <loss>=0.789302888861\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #quality_metric: host=algo-1, epoch=12, train mse <loss>=0.622999050365\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #quality_metric: host=algo-1, epoch=12, train absolute_loss <loss>=0.406785088483\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 560.3058338165283, \"sum\": 560.3058338165283, \"min\": 560.3058338165283}}, \"EndTime\": 1609951070.256628, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951069.695695}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 885, \"sum\": 885.0, \"min\": 885}, \"Total Records Seen\": {\"count\": 1, \"max\": 879280, \"sum\": 879280.0, \"min\": 879280}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1609951070.256923, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 12}, \"StartTime\": 1609951069.696292}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=120485.594581 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #quality_metric: host=algo-1, epoch=13, batch=0 train rmse <loss>=0.690341849301\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #quality_metric: host=algo-1, epoch=13, batch=0 train mse <loss>=0.476571868896\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #quality_metric: host=algo-1, epoch=13, batch=0 train absolute_loss <loss>=0.361689239502\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:50.859] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 600, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #quality_metric: host=algo-1, epoch=13, train rmse <loss>=0.755611185848\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #quality_metric: host=algo-1, epoch=13, train mse <loss>=0.570948264178\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #quality_metric: host=algo-1, epoch=13, train absolute_loss <loss>=0.378862968445\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 602.6740074157715, \"sum\": 602.6740074157715, \"min\": 602.6740074157715}}, \"EndTime\": 1609951070.859928, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951070.256693}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 953, \"sum\": 953.0, \"min\": 953}, \"Total Records Seen\": {\"count\": 1, \"max\": 946840, \"sum\": 946840.0, \"min\": 946840}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1609951070.860207, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 13}, \"StartTime\": 1609951070.257223}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=112012.887417 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #quality_metric: host=algo-1, epoch=14, batch=0 train rmse <loss>=0.654587948316\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #quality_metric: host=algo-1, epoch=14, batch=0 train mse <loss>=0.42848538208\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:50 INFO 140480896128832] #quality_metric: host=algo-1, epoch=14, batch=0 train absolute_loss <loss>=0.336444793701\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:51.415] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 554, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:51 INFO 140480896128832] #quality_metric: host=algo-1, epoch=14, train rmse <loss>=0.724443323317\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:51 INFO 140480896128832] #quality_metric: host=algo-1, epoch=14, train mse <loss>=0.524818128698\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:51 INFO 140480896128832] #quality_metric: host=algo-1, epoch=14, train absolute_loss <loss>=0.354132697162\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 556.0688972473145, \"sum\": 556.0688972473145, \"min\": 556.0688972473145}}, \"EndTime\": 1609951071.416619, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951070.860007}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:51 INFO 140480896128832] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1021, \"sum\": 1021.0, \"min\": 1021}, \"Total Records Seen\": {\"count\": 1, \"max\": 1014400, \"sum\": 1014400.0, \"min\": 1014400}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1609951071.416991, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 14}, \"StartTime\": 1609951070.860519}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:51 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=121380.669384 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:51 INFO 140480896128832] #quality_metric: host=algo-1, epoch=15, batch=0 train rmse <loss>=0.621034834077\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:51 INFO 140480896128832] #quality_metric: host=algo-1, epoch=15, batch=0 train mse <loss>=0.385684265137\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:51 INFO 140480896128832] #quality_metric: host=algo-1, epoch=15, batch=0 train absolute_loss <loss>=0.314225646973\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:51.992] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 574, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:51 INFO 140480896128832] #quality_metric: host=algo-1, epoch=15, train rmse <loss>=0.69560688741\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:51 INFO 140480896128832] #quality_metric: host=algo-1, epoch=15, train mse <loss>=0.483868941812\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:51 INFO 140480896128832] #quality_metric: host=algo-1, epoch=15, train absolute_loss <loss>=0.332219351376\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 576.3199329376221, \"sum\": 576.3199329376221, \"min\": 576.3199329376221}}, \"EndTime\": 1609951071.993644, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951071.41672}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:51 INFO 140480896128832] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1089, \"sum\": 1089.0, \"min\": 1089}, \"Total Records Seen\": {\"count\": 1, \"max\": 1081960, \"sum\": 1081960.0, \"min\": 1081960}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1609951071.993938, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 15}, \"StartTime\": 1609951071.417294}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:51 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=117131.822144 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:52 INFO 140480896128832] #quality_metric: host=algo-1, epoch=16, batch=0 train rmse <loss>=0.589491202589\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:52 INFO 140480896128832] #quality_metric: host=algo-1, epoch=16, batch=0 train mse <loss>=0.34749987793\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:52 INFO 140480896128832] #quality_metric: host=algo-1, epoch=16, batch=0 train absolute_loss <loss>=0.294329559326\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:52.537] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 542, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:52 INFO 140480896128832] #quality_metric: host=algo-1, epoch=16, train rmse <loss>=0.668922088275\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:52 INFO 140480896128832] #quality_metric: host=algo-1, epoch=16, train mse <loss>=0.447456760182\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:52 INFO 140480896128832] #quality_metric: host=algo-1, epoch=16, train absolute_loss <loss>=0.312654312134\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 543.8559055328369, \"sum\": 543.8559055328369, \"min\": 543.8559055328369}}, \"EndTime\": 1609951072.538177, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951071.99371}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:52 INFO 140480896128832] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1157, \"sum\": 1157.0, \"min\": 1157}, \"Total Records Seen\": {\"count\": 1, \"max\": 1149520, \"sum\": 1149520.0, \"min\": 1149520}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 18, \"sum\": 18.0, \"min\": 18}}, \"EndTime\": 1609951072.538395, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 16}, \"StartTime\": 1609951071.99429}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:52 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=124140.108927 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:52 INFO 140480896128832] #quality_metric: host=algo-1, epoch=17, batch=0 train rmse <loss>=0.559785987287\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:52 INFO 140480896128832] #quality_metric: host=algo-1, epoch=17, batch=0 train mse <loss>=0.313360351562\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:52 INFO 140480896128832] #quality_metric: host=algo-1, epoch=17, batch=0 train absolute_loss <loss>=0.276236328125\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:53.138] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 36, \"duration\": 598, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #quality_metric: host=algo-1, epoch=17, train rmse <loss>=0.644222669593\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #quality_metric: host=algo-1, epoch=17, train mse <loss>=0.415022848017\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #quality_metric: host=algo-1, epoch=17, train absolute_loss <loss>=0.295069526224\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 600.2030372619629, \"sum\": 600.2030372619629, \"min\": 600.2030372619629}}, \"EndTime\": 1609951073.138882, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951072.538241}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1225, \"sum\": 1225.0, \"min\": 1225}, \"Total Records Seen\": {\"count\": 1, \"max\": 1217080, \"sum\": 1217080.0, \"min\": 1217080}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 19, \"sum\": 19.0, \"min\": 19}}, \"EndTime\": 1609951073.139157, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 17}, \"StartTime\": 1609951072.538635}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=112480.947966 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #quality_metric: host=algo-1, epoch=18, batch=0 train rmse <loss>=0.531767498408\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #quality_metric: host=algo-1, epoch=18, batch=0 train mse <loss>=0.282776672363\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #quality_metric: host=algo-1, epoch=18, batch=0 train absolute_loss <loss>=0.259967132568\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:53.685] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 38, \"duration\": 544, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #quality_metric: host=algo-1, epoch=18, train rmse <loss>=0.621356309068\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #quality_metric: host=algo-1, epoch=18, train mse <loss>=0.386083662818\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #quality_metric: host=algo-1, epoch=18, train absolute_loss <loss>=0.279204196481\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 546.5748310089111, \"sum\": 546.5748310089111, \"min\": 546.5748310089111}}, \"EndTime\": 1609951073.686137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951073.138938}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1293, \"sum\": 1293.0, \"min\": 1293}, \"Total Records Seen\": {\"count\": 1, \"max\": 1284640, \"sum\": 1284640.0, \"min\": 1284640}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}}, \"EndTime\": 1609951073.686503, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 18}, \"StartTime\": 1609951073.13948}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=123479.607922 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #quality_metric: host=algo-1, epoch=19, batch=0 train rmse <loss>=0.505303311049\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #quality_metric: host=algo-1, epoch=19, batch=0 train mse <loss>=0.255331436157\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:53 INFO 140480896128832] #quality_metric: host=algo-1, epoch=19, batch=0 train absolute_loss <loss>=0.245121139526\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:54.293] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 40, \"duration\": 605, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #quality_metric: host=algo-1, epoch=19, train rmse <loss>=0.600185445849\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #quality_metric: host=algo-1, epoch=19, train mse <loss>=0.36022256941\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #quality_metric: host=algo-1, epoch=19, train absolute_loss <loss>=0.264665476855\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 607.6099872589111, \"sum\": 607.6099872589111, \"min\": 607.6099872589111}}, \"EndTime\": 1609951074.294505, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951073.686204}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1361, \"sum\": 1361.0, \"min\": 1361}, \"Total Records Seen\": {\"count\": 1, \"max\": 1352200, \"sum\": 1352200.0, \"min\": 1352200}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 21, \"sum\": 21.0, \"min\": 21}}, \"EndTime\": 1609951074.294825, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 19}, \"StartTime\": 1609951073.686845}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=111091.753144 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #quality_metric: host=algo-1, epoch=20, batch=0 train rmse <loss>=0.480279815495\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #quality_metric: host=algo-1, epoch=20, batch=0 train mse <loss>=0.230668701172\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #quality_metric: host=algo-1, epoch=20, batch=0 train absolute_loss <loss>=0.231593460083\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:54.841] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 42, \"duration\": 545, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #quality_metric: host=algo-1, epoch=20, train rmse <loss>=0.580587372132\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #quality_metric: host=algo-1, epoch=20, train mse <loss>=0.337081696679\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #quality_metric: host=algo-1, epoch=20, train absolute_loss <loss>=0.251244536905\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 547.2619533538818, \"sum\": 547.2619533538818, \"min\": 547.2619533538818}}, \"EndTime\": 1609951074.842521, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951074.294577}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1429, \"sum\": 1429.0, \"min\": 1429}, \"Total Records Seen\": {\"count\": 1, \"max\": 1419760, \"sum\": 1419760.0, \"min\": 1419760}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}}, \"EndTime\": 1609951074.842836, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 20}, \"StartTime\": 1609951074.295211}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=123325.857012 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #quality_metric: host=algo-1, epoch=21, batch=0 train rmse <loss>=0.456600942593\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #quality_metric: host=algo-1, epoch=21, batch=0 train mse <loss>=0.208484420776\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:54 INFO 140480896128832] #quality_metric: host=algo-1, epoch=21, batch=0 train absolute_loss <loss>=0.219134140015\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:55.403] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 44, \"duration\": 558, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:55 INFO 140480896128832] #quality_metric: host=algo-1, epoch=21, train rmse <loss>=0.562453188874\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:55 INFO 140480896128832] #quality_metric: host=algo-1, epoch=21, train mse <loss>=0.316353589675\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:55 INFO 140480896128832] #quality_metric: host=algo-1, epoch=21, train absolute_loss <loss>=0.238840040319\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 560.8279705047607, \"sum\": 560.8279705047607, \"min\": 560.8279705047607}}, \"EndTime\": 1609951075.404082, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951074.842592}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:55 INFO 140480896128832] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1497, \"sum\": 1497.0, \"min\": 1497}, \"Total Records Seen\": {\"count\": 1, \"max\": 1487320, \"sum\": 1487320.0, \"min\": 1487320}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 23, \"sum\": 23.0, \"min\": 23}}, \"EndTime\": 1609951075.404344, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 21}, \"StartTime\": 1609951074.843208}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:55 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=120367.932817 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:55 INFO 140480896128832] #quality_metric: host=algo-1, epoch=22, batch=0 train rmse <loss>=0.434185846433\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:55 INFO 140480896128832] #quality_metric: host=algo-1, epoch=22, batch=0 train mse <loss>=0.188517349243\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:55 INFO 140480896128832] #quality_metric: host=algo-1, epoch=22, batch=0 train absolute_loss <loss>=0.207415664673\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:56.056] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 46, \"duration\": 650, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #quality_metric: host=algo-1, epoch=22, train rmse <loss>=0.545686140365\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #quality_metric: host=algo-1, epoch=22, train mse <loss>=0.297773363787\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #quality_metric: host=algo-1, epoch=22, train absolute_loss <loss>=0.227323320277\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 652.7009010314941, \"sum\": 652.7009010314941, \"min\": 652.7009010314941}}, \"EndTime\": 1609951076.057382, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951075.404136}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1565, \"sum\": 1565.0, \"min\": 1565}, \"Total Records Seen\": {\"count\": 1, \"max\": 1554880, \"sum\": 1554880.0, \"min\": 1554880}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 24, \"sum\": 24.0, \"min\": 24}}, \"EndTime\": 1609951076.057708, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 22}, \"StartTime\": 1609951075.40463}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=103428.945589 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #quality_metric: host=algo-1, epoch=23, batch=0 train rmse <loss>=0.412966248544\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #quality_metric: host=algo-1, epoch=23, batch=0 train mse <loss>=0.170541122437\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #quality_metric: host=algo-1, epoch=23, batch=0 train absolute_loss <loss>=0.196411117554\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:56.599] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 48, \"duration\": 539, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #quality_metric: host=algo-1, epoch=23, train rmse <loss>=0.530198786732\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #quality_metric: host=algo-1, epoch=23, train mse <loss>=0.281110753452\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #quality_metric: host=algo-1, epoch=23, train absolute_loss <loss>=0.216657873041\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 541.6278839111328, \"sum\": 541.6278839111328, \"min\": 541.6278839111328}}, \"EndTime\": 1609951076.599742, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951076.057456}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1633, \"sum\": 1633.0, \"min\": 1633}, \"Total Records Seen\": {\"count\": 1, \"max\": 1622440, \"sum\": 1622440.0, \"min\": 1622440}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 25, \"sum\": 25.0, \"min\": 25}}, \"EndTime\": 1609951076.60004, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 23}, \"StartTime\": 1609951076.058076}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=124621.85957 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #quality_metric: host=algo-1, epoch=24, batch=0 train rmse <loss>=0.392882305974\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #quality_metric: host=algo-1, epoch=24, batch=0 train mse <loss>=0.154356506348\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:56 INFO 140480896128832] #quality_metric: host=algo-1, epoch=24, batch=0 train absolute_loss <loss>=0.186191574097\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:57.191] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 50, \"duration\": 589, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #quality_metric: host=algo-1, epoch=24, train rmse <loss>=0.515910172697\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #quality_metric: host=algo-1, epoch=24, train mse <loss>=0.266163306292\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #quality_metric: host=algo-1, epoch=24, train absolute_loss <loss>=0.206791166867\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 591.6681289672852, \"sum\": 591.6681289672852, \"min\": 591.6681289672852}}, \"EndTime\": 1609951077.192076, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951076.599808}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1701, \"sum\": 1701.0, \"min\": 1701}, \"Total Records Seen\": {\"count\": 1, \"max\": 1690000, \"sum\": 1690000.0, \"min\": 1690000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 26, \"sum\": 26.0, \"min\": 26}}, \"EndTime\": 1609951077.192407, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 24}, \"StartTime\": 1609951076.600377}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=114093.085714 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #quality_metric: host=algo-1, epoch=25, batch=0 train rmse <loss>=0.373879694556\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #quality_metric: host=algo-1, epoch=25, batch=0 train mse <loss>=0.139786026001\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #quality_metric: host=algo-1, epoch=25, batch=0 train absolute_loss <loss>=0.176588363647\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:57.736] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 52, \"duration\": 542, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #quality_metric: host=algo-1, epoch=25, train rmse <loss>=0.502744010199\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #quality_metric: host=algo-1, epoch=25, train mse <loss>=0.252751539791\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #quality_metric: host=algo-1, epoch=25, train absolute_loss <loss>=0.197605554693\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 544.8808670043945, \"sum\": 544.8808670043945, \"min\": 544.8808670043945}}, \"EndTime\": 1609951077.737651, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951077.192162}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1769, \"sum\": 1769.0, \"min\": 1769}, \"Total Records Seen\": {\"count\": 1, \"max\": 1757560, \"sum\": 1757560.0, \"min\": 1757560}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 27, \"sum\": 27.0, \"min\": 27}}, \"EndTime\": 1609951077.737959, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 25}, \"StartTime\": 1609951077.19273}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=123877.824237 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #quality_metric: host=algo-1, epoch=26, batch=0 train rmse <loss>=0.355907320882\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #quality_metric: host=algo-1, epoch=26, batch=0 train mse <loss>=0.126670021057\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:57 INFO 140480896128832] #quality_metric: host=algo-1, epoch=26, batch=0 train absolute_loss <loss>=0.167616851807\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:58.374] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 54, \"duration\": 634, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #quality_metric: host=algo-1, epoch=26, train rmse <loss>=0.490627176817\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #quality_metric: host=algo-1, epoch=26, train mse <loss>=0.240715026631\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #quality_metric: host=algo-1, epoch=26, train absolute_loss <loss>=0.189068051282\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 636.5039348602295, \"sum\": 636.5039348602295, \"min\": 636.5039348602295}}, \"EndTime\": 1609951078.374827, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951077.737723}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1837, \"sum\": 1837.0, \"min\": 1837}, \"Total Records Seen\": {\"count\": 1, \"max\": 1825120, \"sum\": 1825120.0, \"min\": 1825120}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 28, \"sum\": 28.0, \"min\": 28}}, \"EndTime\": 1609951078.375186, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 26}, \"StartTime\": 1609951077.738292}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=106053.488078 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #quality_metric: host=algo-1, epoch=27, batch=0 train rmse <loss>=0.338916096524\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #quality_metric: host=algo-1, epoch=27, batch=0 train mse <loss>=0.114864120483\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #quality_metric: host=algo-1, epoch=27, batch=0 train absolute_loss <loss>=0.159486785889\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:58.944] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 56, \"duration\": 567, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #quality_metric: host=algo-1, epoch=27, train rmse <loss>=0.479489328235\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #quality_metric: host=algo-1, epoch=27, train mse <loss>=0.229910015892\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #quality_metric: host=algo-1, epoch=27, train absolute_loss <loss>=0.181189951728\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 569.7610378265381, \"sum\": 569.7610378265381, \"min\": 569.7610378265381}}, \"EndTime\": 1609951078.945285, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951078.374926}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1905, \"sum\": 1905.0, \"min\": 1905}, \"Total Records Seen\": {\"count\": 1, \"max\": 1892680, \"sum\": 1892680.0, \"min\": 1892680}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 29, \"sum\": 29.0, \"min\": 29}}, \"EndTime\": 1609951078.945574, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 27}, \"StartTime\": 1609951078.375493}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=118480.389617 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #quality_metric: host=algo-1, epoch=28, batch=0 train rmse <loss>=0.322857919251\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #quality_metric: host=algo-1, epoch=28, batch=0 train mse <loss>=0.104237236023\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:58 INFO 140480896128832] #quality_metric: host=algo-1, epoch=28, batch=0 train absolute_loss <loss>=0.151940185547\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:37:59.496] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 58, \"duration\": 549, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:59 INFO 140480896128832] #quality_metric: host=algo-1, epoch=28, train rmse <loss>=0.46926240436\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:59 INFO 140480896128832] #quality_metric: host=algo-1, epoch=28, train mse <loss>=0.220207204146\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:59 INFO 140480896128832] #quality_metric: host=algo-1, epoch=28, train absolute_loss <loss>=0.173866655238\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 551.5270233154297, \"sum\": 551.5270233154297, \"min\": 551.5270233154297}}, \"EndTime\": 1609951079.497444, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951078.945364}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:59 INFO 140480896128832] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1973, \"sum\": 1973.0, \"min\": 1973}, \"Total Records Seen\": {\"count\": 1, \"max\": 1960240, \"sum\": 1960240.0, \"min\": 1960240}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}}, \"EndTime\": 1609951079.497763, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 28}, \"StartTime\": 1609951078.945885}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:59 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=122393.303024 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:59 INFO 140480896128832] #quality_metric: host=algo-1, epoch=29, batch=0 train rmse <loss>=0.307685706655\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:59 INFO 140480896128832] #quality_metric: host=algo-1, epoch=29, batch=0 train mse <loss>=0.0946704940796\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:37:59 INFO 140480896128832] #quality_metric: host=algo-1, epoch=29, batch=0 train absolute_loss <loss>=0.144816055298\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:00.046] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 60, \"duration\": 546, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #quality_metric: host=algo-1, epoch=29, train rmse <loss>=0.459881075635\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #quality_metric: host=algo-1, epoch=29, train mse <loss>=0.211490603727\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #quality_metric: host=algo-1, epoch=29, train absolute_loss <loss>=0.167053077922\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 548.9392280578613, \"sum\": 548.9392280578613, \"min\": 548.9392280578613}}, \"EndTime\": 1609951080.047056, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951079.497523}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2041, \"sum\": 2041.0, \"min\": 2041}, \"Total Records Seen\": {\"count\": 1, \"max\": 2027800, \"sum\": 2027800.0, \"min\": 2027800}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}}, \"EndTime\": 1609951080.047274, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 29}, \"StartTime\": 1609951079.498086}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=122986.397552 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #quality_metric: host=algo-1, epoch=30, batch=0 train rmse <loss>=0.293353523369\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #quality_metric: host=algo-1, epoch=30, batch=0 train mse <loss>=0.0860562896729\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #quality_metric: host=algo-1, epoch=30, batch=0 train absolute_loss <loss>=0.138076889038\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:00.597] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 62, \"duration\": 548, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #quality_metric: host=algo-1, epoch=30, train rmse <loss>=0.451282878124\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #quality_metric: host=algo-1, epoch=30, train mse <loss>=0.203656236088\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #quality_metric: host=algo-1, epoch=30, train absolute_loss <loss>=0.160724189646\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 550.5549907684326, \"sum\": 550.5549907684326, \"min\": 550.5549907684326}}, \"EndTime\": 1609951080.598173, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951080.047121}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2109, \"sum\": 2109.0, \"min\": 2109}, \"Total Records Seen\": {\"count\": 1, \"max\": 2095360, \"sum\": 2095360.0, \"min\": 2095360}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 32, \"sum\": 32.0, \"min\": 32}}, \"EndTime\": 1609951080.598398, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 30}, \"StartTime\": 1609951080.047571}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=122624.334117 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #quality_metric: host=algo-1, epoch=31, batch=0 train rmse <loss>=0.279816728285\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #quality_metric: host=algo-1, epoch=31, batch=0 train mse <loss>=0.0782974014282\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:00 INFO 140480896128832] #quality_metric: host=algo-1, epoch=31, batch=0 train absolute_loss <loss>=0.131800186157\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:01.208] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 64, \"duration\": 608, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #quality_metric: host=algo-1, epoch=31, train rmse <loss>=0.443408536401\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #quality_metric: host=algo-1, epoch=31, train mse <loss>=0.196611130153\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #quality_metric: host=algo-1, epoch=31, train absolute_loss <loss>=0.15483084185\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 610.194206237793, \"sum\": 610.194206237793, \"min\": 610.194206237793}}, \"EndTime\": 1609951081.20888, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951080.598243}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2177, \"sum\": 2177.0, \"min\": 2177}, \"Total Records Seen\": {\"count\": 1, \"max\": 2162920, \"sum\": 2162920.0, \"min\": 2162920}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 33, \"sum\": 33.0, \"min\": 33}}, \"EndTime\": 1609951081.209176, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 31}, \"StartTime\": 1609951080.598655}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=110637.103112 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #quality_metric: host=algo-1, epoch=32, batch=0 train rmse <loss>=0.267032589984\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #quality_metric: host=algo-1, epoch=32, batch=0 train mse <loss>=0.0713064041138\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #quality_metric: host=algo-1, epoch=32, batch=0 train absolute_loss <loss>=0.125977134705\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:01.871] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 66, \"duration\": 660, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #quality_metric: host=algo-1, epoch=32, train rmse <loss>=0.436202256461\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #quality_metric: host=algo-1, epoch=32, train mse <loss>=0.190272408542\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #quality_metric: host=algo-1, epoch=32, train absolute_loss <loss>=0.149310370053\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 662.8408432006836, \"sum\": 662.8408432006836, \"min\": 662.8408432006836}}, \"EndTime\": 1609951081.872402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951081.208938}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2245, \"sum\": 2245.0, \"min\": 2245}, \"Total Records Seen\": {\"count\": 1, \"max\": 2230480, \"sum\": 2230480.0, \"min\": 2230480}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 34, \"sum\": 34.0, \"min\": 34}}, \"EndTime\": 1609951081.872718, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 32}, \"StartTime\": 1609951081.209509}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=101849.782651 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #quality_metric: host=algo-1, epoch=33, batch=0 train rmse <loss>=0.254960192397\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #quality_metric: host=algo-1, epoch=33, batch=0 train mse <loss>=0.065004699707\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:01 INFO 140480896128832] #quality_metric: host=algo-1, epoch=33, batch=0 train absolute_loss <loss>=0.120465614319\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:02.458] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 68, \"duration\": 583, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:02 INFO 140480896128832] #quality_metric: host=algo-1, epoch=33, train rmse <loss>=0.429611540485\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:02 INFO 140480896128832] #quality_metric: host=algo-1, epoch=33, train mse <loss>=0.184566075718\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:02 INFO 140480896128832] #quality_metric: host=algo-1, epoch=33, train absolute_loss <loss>=0.144124530343\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 585.8728885650635, \"sum\": 585.8728885650635, \"min\": 585.8728885650635}}, \"EndTime\": 1609951082.458985, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951081.872473}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:02 INFO 140480896128832] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2313, \"sum\": 2313.0, \"min\": 2313}, \"Total Records Seen\": {\"count\": 1, \"max\": 2298040, \"sum\": 2298040.0, \"min\": 2298040}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 35, \"sum\": 35.0, \"min\": 35}}, \"EndTime\": 1609951082.459354, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 33}, \"StartTime\": 1609951081.873066}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:02 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=115194.545732 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:02 INFO 140480896128832] #quality_metric: host=algo-1, epoch=34, batch=0 train rmse <loss>=0.243560819327\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:02 INFO 140480896128832] #quality_metric: host=algo-1, epoch=34, batch=0 train mse <loss>=0.0593218727112\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:02 INFO 140480896128832] #quality_metric: host=algo-1, epoch=34, batch=0 train absolute_loss <loss>=0.115284858704\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:03.024] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 70, \"duration\": 562, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #quality_metric: host=algo-1, epoch=34, train rmse <loss>=0.423587504786\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #quality_metric: host=algo-1, epoch=34, train mse <loss>=0.179426374211\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #quality_metric: host=algo-1, epoch=34, train absolute_loss <loss>=0.139234633838\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 565.086841583252, \"sum\": 565.086841583252, \"min\": 565.086841583252}}, \"EndTime\": 1609951083.024847, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951082.459094}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2381, \"sum\": 2381.0, \"min\": 2381}, \"Total Records Seen\": {\"count\": 1, \"max\": 2365600, \"sum\": 2365600.0, \"min\": 2365600}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 36, \"sum\": 36.0, \"min\": 36}}, \"EndTime\": 1609951083.025112, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 34}, \"StartTime\": 1609951082.459728}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=119459.368251 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #quality_metric: host=algo-1, epoch=35, batch=0 train rmse <loss>=0.232797744591\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #quality_metric: host=algo-1, epoch=35, batch=0 train mse <loss>=0.0541947898865\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #quality_metric: host=algo-1, epoch=35, batch=0 train absolute_loss <loss>=0.110486656189\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:03.572] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 72, \"duration\": 546, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #quality_metric: host=algo-1, epoch=35, train rmse <loss>=0.418084480189\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #quality_metric: host=algo-1, epoch=35, train mse <loss>=0.174794632575\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #quality_metric: host=algo-1, epoch=35, train absolute_loss <loss>=0.134628054675\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 547.7900505065918, \"sum\": 547.7900505065918, \"min\": 547.7900505065918}}, \"EndTime\": 1609951083.573251, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951083.024923}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2449, \"sum\": 2449.0, \"min\": 2449}, \"Total Records Seen\": {\"count\": 1, \"max\": 2433160, \"sum\": 2433160.0, \"min\": 2433160}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 37, \"sum\": 37.0, \"min\": 37}}, \"EndTime\": 1609951083.57347, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 35}, \"StartTime\": 1609951083.025431}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=123246.20356 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #quality_metric: host=algo-1, epoch=36, batch=0 train rmse <loss>=0.222636392344\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #quality_metric: host=algo-1, epoch=36, batch=0 train mse <loss>=0.0495669631958\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:03 INFO 140480896128832] #quality_metric: host=algo-1, epoch=36, batch=0 train absolute_loss <loss>=0.105923332214\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:04.125] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 74, \"duration\": 550, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #quality_metric: host=algo-1, epoch=36, train rmse <loss>=0.413060114654\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #quality_metric: host=algo-1, epoch=36, train mse <loss>=0.170618658318\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #quality_metric: host=algo-1, epoch=36, train absolute_loss <loss>=0.130274570241\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 552.6189804077148, \"sum\": 552.6189804077148, \"min\": 552.6189804077148}}, \"EndTime\": 1609951084.126402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951083.573319}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #progress_metric: host=algo-1, completed 74 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2517, \"sum\": 2517.0, \"min\": 2517}, \"Total Records Seen\": {\"count\": 1, \"max\": 2500720, \"sum\": 2500720.0, \"min\": 2500720}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 38, \"sum\": 38.0, \"min\": 38}}, \"EndTime\": 1609951084.126692, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 36}, \"StartTime\": 1609951083.573752}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=122152.081973 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #quality_metric: host=algo-1, epoch=37, batch=0 train rmse <loss>=0.213044167681\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #quality_metric: host=algo-1, epoch=37, batch=0 train mse <loss>=0.0453878173828\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #quality_metric: host=algo-1, epoch=37, batch=0 train absolute_loss <loss>=0.101575691223\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:04.674] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 76, \"duration\": 546, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #quality_metric: host=algo-1, epoch=37, train rmse <loss>=0.408475086631\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #quality_metric: host=algo-1, epoch=37, train mse <loss>=0.166851896398\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #quality_metric: host=algo-1, epoch=37, train absolute_loss <loss>=0.126145215315\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 547.9991436004639, \"sum\": 547.9991436004639, \"min\": 547.9991436004639}}, \"EndTime\": 1609951084.675053, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951084.126488}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2585, \"sum\": 2585.0, \"min\": 2585}, \"Total Records Seen\": {\"count\": 1, \"max\": 2568280, \"sum\": 2568280.0, \"min\": 2568280}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 39, \"sum\": 39.0, \"min\": 39}}, \"EndTime\": 1609951084.675334, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 37}, \"StartTime\": 1609951084.127022}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=123180.145199 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #quality_metric: host=algo-1, epoch=38, batch=0 train rmse <loss>=0.20399036295\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #quality_metric: host=algo-1, epoch=38, batch=0 train mse <loss>=0.0416120681763\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:04 INFO 140480896128832] #quality_metric: host=algo-1, epoch=38, batch=0 train absolute_loss <loss>=0.0974811553955\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:05.225] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 78, \"duration\": 548, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #quality_metric: host=algo-1, epoch=38, train rmse <loss>=0.404292901607\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #quality_metric: host=algo-1, epoch=38, train mse <loss>=0.16345275029\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #quality_metric: host=algo-1, epoch=38, train absolute_loss <loss>=0.122231900944\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 550.3520965576172, \"sum\": 550.3520965576172, \"min\": 550.3520965576172}}, \"EndTime\": 1609951085.226036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951084.67513}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2653, \"sum\": 2653.0, \"min\": 2653}, \"Total Records Seen\": {\"count\": 1, \"max\": 2635840, \"sum\": 2635840.0, \"min\": 2635840}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 40, \"sum\": 40.0, \"min\": 40}}, \"EndTime\": 1609951085.226325, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 38}, \"StartTime\": 1609951084.675651}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=122653.685789 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #quality_metric: host=algo-1, epoch=39, batch=0 train rmse <loss>=0.195446038333\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #quality_metric: host=algo-1, epoch=39, batch=0 train mse <loss>=0.0381991539001\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #quality_metric: host=algo-1, epoch=39, batch=0 train absolute_loss <loss>=0.0936378860474\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:05.769] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 80, \"duration\": 541, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #quality_metric: host=algo-1, epoch=39, train rmse <loss>=0.400479808885\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #quality_metric: host=algo-1, epoch=39, train mse <loss>=0.160384077325\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #quality_metric: host=algo-1, epoch=39, train absolute_loss <loss>=0.118525427538\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 543.1828498840332, \"sum\": 543.1828498840332, \"min\": 543.1828498840332}}, \"EndTime\": 1609951085.769798, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951085.226115}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2721, \"sum\": 2721.0, \"min\": 2721}, \"Total Records Seen\": {\"count\": 1, \"max\": 2703400, \"sum\": 2703400.0, \"min\": 2703400}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 41, \"sum\": 41.0, \"min\": 41}}, \"EndTime\": 1609951085.770013, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 39}, \"StartTime\": 1609951085.226584}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=124295.57096 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #quality_metric: host=algo-1, epoch=40, batch=0 train rmse <loss>=0.187383702133\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #quality_metric: host=algo-1, epoch=40, batch=0 train mse <loss>=0.035112651825\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:05 INFO 140480896128832] #quality_metric: host=algo-1, epoch=40, batch=0 train absolute_loss <loss>=0.089987197876\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:06.374] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 82, \"duration\": 602, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #quality_metric: host=algo-1, epoch=40, train rmse <loss>=0.397004486418\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #quality_metric: host=algo-1, epoch=40, train mse <loss>=0.157612562236\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #quality_metric: host=algo-1, epoch=40, train absolute_loss <loss>=0.115008657343\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 604.5958995819092, \"sum\": 604.5958995819092, \"min\": 604.5958995819092}}, \"EndTime\": 1609951086.374897, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951085.769866}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2789, \"sum\": 2789.0, \"min\": 2789}, \"Total Records Seen\": {\"count\": 1, \"max\": 2770960, \"sum\": 2770960.0, \"min\": 2770960}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 42, \"sum\": 42.0, \"min\": 42}}, \"EndTime\": 1609951086.37522, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 40}, \"StartTime\": 1609951085.770269}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=111657.757405 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #quality_metric: host=algo-1, epoch=41, batch=0 train rmse <loss>=0.179777374348\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #quality_metric: host=algo-1, epoch=41, batch=0 train mse <loss>=0.0323199043274\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #quality_metric: host=algo-1, epoch=41, batch=0 train absolute_loss <loss>=0.0865175628662\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:06.928] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 84, \"duration\": 551, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #quality_metric: host=algo-1, epoch=41, train rmse <loss>=0.39383800061\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #quality_metric: host=algo-1, epoch=41, train mse <loss>=0.155108370725\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #quality_metric: host=algo-1, epoch=41, train absolute_loss <loss>=0.111668310502\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 553.2779693603516, \"sum\": 553.2779693603516, \"min\": 553.2779693603516}}, \"EndTime\": 1609951086.928834, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951086.374993}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #progress_metric: host=algo-1, completed 84 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2857, \"sum\": 2857.0, \"min\": 2857}, \"Total Records Seen\": {\"count\": 1, \"max\": 2838520, \"sum\": 2838520.0, \"min\": 2838520}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 43, \"sum\": 43.0, \"min\": 43}}, \"EndTime\": 1609951086.929052, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 41}, \"StartTime\": 1609951086.375526}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=122009.811965 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #quality_metric: host=algo-1, epoch=42, batch=0 train rmse <loss>=0.172602353897\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #quality_metric: host=algo-1, epoch=42, batch=0 train mse <loss>=0.0297915725708\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:06 INFO 140480896128832] #quality_metric: host=algo-1, epoch=42, batch=0 train absolute_loss <loss>=0.0832685546875\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:07.492] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 86, \"duration\": 562, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:07 INFO 140480896128832] #quality_metric: host=algo-1, epoch=42, train rmse <loss>=0.390953576551\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:07 INFO 140480896128832] #quality_metric: host=algo-1, epoch=42, train mse <loss>=0.152844699018\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:07 INFO 140480896128832] #quality_metric: host=algo-1, epoch=42, train absolute_loss <loss>=0.108503075095\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 564.0389919281006, \"sum\": 564.0389919281006, \"min\": 564.0389919281006}}, \"EndTime\": 1609951087.493435, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951086.928902}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:07 INFO 140480896128832] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2925, \"sum\": 2925.0, \"min\": 2925}, \"Total Records Seen\": {\"count\": 1, \"max\": 2906080, \"sum\": 2906080.0, \"min\": 2906080}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 44, \"sum\": 44.0, \"min\": 44}}, \"EndTime\": 1609951087.493661, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 42}, \"StartTime\": 1609951086.929367}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:07 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=119700.224027 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:07 INFO 140480896128832] #quality_metric: host=algo-1, epoch=43, batch=0 train rmse <loss>=0.165835075305\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:07 INFO 140480896128832] #quality_metric: host=algo-1, epoch=43, batch=0 train mse <loss>=0.0275012722015\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:07 INFO 140480896128832] #quality_metric: host=algo-1, epoch=43, batch=0 train absolute_loss <loss>=0.0802388534546\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:08.103] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 88, \"duration\": 608, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #quality_metric: host=algo-1, epoch=43, train rmse <loss>=0.38832642509\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #quality_metric: host=algo-1, epoch=43, train mse <loss>=0.150797412424\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #quality_metric: host=algo-1, epoch=43, train absolute_loss <loss>=0.105499174342\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 610.7749938964844, \"sum\": 610.7749938964844, \"min\": 610.7749938964844}}, \"EndTime\": 1609951088.104762, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951087.4935}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2993, \"sum\": 2993.0, \"min\": 2993}, \"Total Records Seen\": {\"count\": 1, \"max\": 2973640, \"sum\": 2973640.0, \"min\": 2973640}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}}, \"EndTime\": 1609951088.105054, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 43}, \"StartTime\": 1609951087.493916}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=110519.301284 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #quality_metric: host=algo-1, epoch=44, batch=0 train rmse <loss>=0.159452986243\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #quality_metric: host=algo-1, epoch=44, batch=0 train mse <loss>=0.0254252548218\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #quality_metric: host=algo-1, epoch=44, batch=0 train absolute_loss <loss>=0.0773541946411\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:08.652] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 90, \"duration\": 545, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #quality_metric: host=algo-1, epoch=44, train rmse <loss>=0.385933757654\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #quality_metric: host=algo-1, epoch=44, train mse <loss>=0.148944865297\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #quality_metric: host=algo-1, epoch=44, train absolute_loss <loss>=0.102652058321\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 547.0719337463379, \"sum\": 547.0719337463379, \"min\": 547.0719337463379}}, \"EndTime\": 1609951088.65255, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951088.104816}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3061, \"sum\": 3061.0, \"min\": 3061}, \"Total Records Seen\": {\"count\": 1, \"max\": 3041200, \"sum\": 3041200.0, \"min\": 3041200}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 46, \"sum\": 46.0, \"min\": 46}}, \"EndTime\": 1609951088.652769, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 44}, \"StartTime\": 1609951088.105449}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=123401.959087 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #quality_metric: host=algo-1, epoch=45, batch=0 train rmse <loss>=0.153434701805\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #quality_metric: host=algo-1, epoch=45, batch=0 train mse <loss>=0.0235422077179\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:08 INFO 140480896128832] #quality_metric: host=algo-1, epoch=45, batch=0 train absolute_loss <loss>=0.0746034164429\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:09.213] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 92, \"duration\": 559, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #quality_metric: host=algo-1, epoch=45, train rmse <loss>=0.383754484878\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #quality_metric: host=algo-1, epoch=45, train mse <loss>=0.147267504664\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #quality_metric: host=algo-1, epoch=45, train absolute_loss <loss>=0.0999453843061\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 561.025857925415, \"sum\": 561.025857925415, \"min\": 561.025857925415}}, \"EndTime\": 1609951089.21407, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951088.652614}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3129, \"sum\": 3129.0, \"min\": 3129}, \"Total Records Seen\": {\"count\": 1, \"max\": 3108760, \"sum\": 3108760.0, \"min\": 3108760}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 47, \"sum\": 47.0, \"min\": 47}}, \"EndTime\": 1609951089.21437, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 45}, \"StartTime\": 1609951088.653015}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=120324.437284 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #quality_metric: host=algo-1, epoch=46, batch=0 train rmse <loss>=0.14775959899\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #quality_metric: host=algo-1, epoch=46, batch=0 train mse <loss>=0.0218328990936\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #quality_metric: host=algo-1, epoch=46, batch=0 train absolute_loss <loss>=0.071972328186\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:09.757] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 94, \"duration\": 541, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #quality_metric: host=algo-1, epoch=46, train rmse <loss>=0.381769257009\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #quality_metric: host=algo-1, epoch=46, train mse <loss>=0.145747765597\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #quality_metric: host=algo-1, epoch=46, train absolute_loss <loss>=0.0973722316518\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 543.8380241394043, \"sum\": 543.8380241394043, \"min\": 543.8380241394043}}, \"EndTime\": 1609951089.758616, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951089.214132}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #progress_metric: host=algo-1, completed 94 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3197, \"sum\": 3197.0, \"min\": 3197}, \"Total Records Seen\": {\"count\": 1, \"max\": 3176320, \"sum\": 3176320.0, \"min\": 3176320}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 48, \"sum\": 48.0, \"min\": 48}}, \"EndTime\": 1609951089.758912, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 46}, \"StartTime\": 1609951089.214706}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=124112.705217 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #quality_metric: host=algo-1, epoch=47, batch=0 train rmse <loss>=0.142407927633\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #quality_metric: host=algo-1, epoch=47, batch=0 train mse <loss>=0.0202800178528\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:09 INFO 140480896128832] #quality_metric: host=algo-1, epoch=47, batch=0 train absolute_loss <loss>=0.0694766845703\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:10.314] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 96, \"duration\": 554, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #quality_metric: host=algo-1, epoch=47, train rmse <loss>=0.379960254869\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #quality_metric: host=algo-1, epoch=47, train mse <loss>=0.14436979528\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #quality_metric: host=algo-1, epoch=47, train absolute_loss <loss>=0.0949264124702\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 556.3921928405762, \"sum\": 556.3921928405762, \"min\": 556.3921928405762}}, \"EndTime\": 1609951090.315626, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951089.758675}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3265, \"sum\": 3265.0, \"min\": 3265}, \"Total Records Seen\": {\"count\": 1, \"max\": 3243880, \"sum\": 3243880.0, \"min\": 3243880}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 49, \"sum\": 49.0, \"min\": 49}}, \"EndTime\": 1609951090.315912, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 47}, \"StartTime\": 1609951089.759201}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=121327.087693 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #quality_metric: host=algo-1, epoch=48, batch=0 train rmse <loss>=0.137360977637\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #quality_metric: host=algo-1, epoch=48, batch=0 train mse <loss>=0.0188680381775\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #quality_metric: host=algo-1, epoch=48, batch=0 train absolute_loss <loss>=0.0670842514038\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:10.852] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 98, \"duration\": 534, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #quality_metric: host=algo-1, epoch=48, train rmse <loss>=0.378311131091\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #quality_metric: host=algo-1, epoch=48, train mse <loss>=0.143119311908\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #quality_metric: host=algo-1, epoch=48, train absolute_loss <loss>=0.092600146518\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 536.8731021881104, \"sum\": 536.8731021881104, \"min\": 536.8731021881104}}, \"EndTime\": 1609951090.853162, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951090.315704}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3333, \"sum\": 3333.0, \"min\": 3333}, \"Total Records Seen\": {\"count\": 1, \"max\": 3311440, \"sum\": 3311440.0, \"min\": 3311440}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 50, \"sum\": 50.0, \"min\": 50}}, \"EndTime\": 1609951090.853527, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 48}, \"StartTime\": 1609951090.316218}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=125708.212368 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #quality_metric: host=algo-1, epoch=49, batch=0 train rmse <loss>=0.132600617982\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #quality_metric: host=algo-1, epoch=49, batch=0 train mse <loss>=0.0175829238892\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:10 INFO 140480896128832] #quality_metric: host=algo-1, epoch=49, batch=0 train absolute_loss <loss>=0.0648022232056\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:11.471] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 100, \"duration\": 616, \"num_examples\": 68, \"num_bytes\": 4323840}\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] #quality_metric: host=algo-1, epoch=49, train rmse <loss>=0.376807008002\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] #quality_metric: host=algo-1, epoch=49, train mse <loss>=0.141983521279\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] #quality_metric: host=algo-1, epoch=49, train absolute_loss <loss>=0.0903891548269\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] #quality_metric: host=algo-1, train rmse <loss>=0.376807008002\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] #quality_metric: host=algo-1, train mse <loss>=0.141983521279\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] #quality_metric: host=algo-1, train absolute_loss <loss>=0.0903891548269\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 618.8571453094482, \"sum\": 618.8571453094482, \"min\": 618.8571453094482}}, \"EndTime\": 1609951091.472781, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951090.853217}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 68, \"sum\": 68.0, \"min\": 68}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Total Batches Seen\": {\"count\": 1, \"max\": 3401, \"sum\": 3401.0, \"min\": 3401}, \"Total Records Seen\": {\"count\": 1, \"max\": 3379000, \"sum\": 3379000.0, \"min\": 3379000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 67560, \"sum\": 67560.0, \"min\": 67560}, \"Reset Count\": {\"count\": 1, \"max\": 51, \"sum\": 51.0, \"min\": 51}}, \"EndTime\": 1609951091.473097, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 49}, \"StartTime\": 1609951090.853868}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] #throughput_metric: host=algo-1, train throughput=109074.887868 records/second\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 WARNING 140480896128832] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 2.7060508728027344, \"sum\": 2.7060508728027344, \"min\": 2.7060508728027344}}, \"EndTime\": 1609951091.476221, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951091.472857}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] Saved checkpoint to \"/tmp/tmp1y4V2H/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:11.491] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 29568, \"num_examples\": 1, \"num_bytes\": 64000}\u001b[0m\n",
      "\u001b[34m[2021-01-06 16:38:11.718] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 226, \"num_examples\": 34, \"num_bytes\": 2129664}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 34, \"sum\": 34.0, \"min\": 34}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 34, \"sum\": 34.0, \"min\": 34}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 33276, \"sum\": 33276.0, \"min\": 33276}, \"Total Batches Seen\": {\"count\": 1, \"max\": 34, \"sum\": 34.0, \"min\": 34}, \"Total Records Seen\": {\"count\": 1, \"max\": 33276, \"sum\": 33276.0, \"min\": 33276}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 33276, \"sum\": 33276.0, \"min\": 33276}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1609951091.718686, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951091.491593}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] #test_score (algo-1) : ('rmse', 0.20213288418716993)\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] #test_score (algo-1) : ('mse', 0.040857702869823855)\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] #test_score (algo-1) : ('absolute_loss', 0.0882503944802333)\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] #quality_metric: host=algo-1, test rmse <loss>=0.202132884187\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] #quality_metric: host=algo-1, test mse <loss>=0.0408577028698\u001b[0m\n",
      "\u001b[34m[01/06/2021 16:38:11 INFO 140480896128832] #quality_metric: host=algo-1, test absolute_loss <loss>=0.0882503944802\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 29856.974840164185, \"sum\": 29856.974840164185, \"min\": 29856.974840164185}, \"setuptime\": {\"count\": 1, \"max\": 49.22604560852051, \"sum\": 49.22604560852051, \"min\": 49.22604560852051}}, \"EndTime\": 1609951091.720149, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1609951091.476286}\n",
      "\u001b[0m\n",
      "Training seconds: 147\n",
      "Billable seconds: 147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "fm_regression_pred = tuner_regression.deploy(instance_type='ml.m5.large', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm_serializer(data):\n",
    "    js = {\"instances\": []}\n",
    "    for row in data:\n",
    "        js[\"instances\"].append({\"features\": row.tolist()})\n",
    "    return json.dumps(js).encode()\n",
    "\n",
    "\n",
    "fm_regression_pred.serializer = fm_serializer\n",
    "fm_regression_pred.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and  Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_regression_result = fm_regression_pred.predict(X_test[1002:1009].toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actuals = pd.DataFrame(y_test[1002:1009])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = fm_regression_result.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([[{'score': 4.0022454261779785}, {'score': 3.9643962383270264}, {'score': 4.015176773071289}, {'score': 2.282944440841675}, {'score': 1.9619837999343872}, {'score': 4.0184173583984375}, {'score': 4.961643218994141}]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Predictions vs Actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  4.0\n",
       "1  4.0\n",
       "2  4.0\n",
       "3  2.0\n",
       "4  2.0\n",
       "5  4.0\n",
       "6  5.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
